{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MNIST digits classification using a FFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using FFNN with: 1 input layer, 1 hidden layer of 20 neurons, 1 output layer of 10 neurons. The data is the MNIST dataset in a txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input layer: (60 000 x 784) with float values between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer: ((784 + 1) x 20), +1 is for the bias, with Sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer: (60 000 x 10), with Softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now the best model gave me 92,55% on the test, limited to 10000 epochs, in 36min47 (slow Intel i5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #0 Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_images = []\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "with open('data/MNIST_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = list(map(int, line.strip().split(',')))\n",
    "        train_labels.append(values[0])\n",
    "        train_images.append(values[1:])\n",
    "\n",
    "with open('data/MNIST_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = list(map(int, line.strip().split(',')))\n",
    "        test_labels.append(values[0])\n",
    "        test_images.append(values[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #1 Initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 60000  #nb of training samples, might be equal to datasize if the X is limited in train()\n",
    "N = 784    #features\n",
    "K = 20     #nb of hidden neurons\n",
    "J = 10     #nb of outputs\n",
    "\n",
    "I_test = 10000     #nb of testing samples\n",
    "\n",
    "error = 1E5        #error initialization\n",
    "thresh = 1E-2      #error threshold\n",
    "alpha1 = 1E-5      #learning rate for the hidden layer\n",
    "alpha2 = 1E-5      #learning rate for the output layer\n",
    "max_itera = 1E4    #maximum iterations for the while loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #2 Initializing the weights and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.random.randn(N+1,K)*0.01  #(N+1) x K  -> weights for the hidden layer\n",
    "W = np.random.randn(K+1,J)*0.01  #(K+1) x J  -> weights for the output layer\n",
    "\n",
    "#X_train with (0,1) values\n",
    "X = np.array(train_images)/255\n",
    "\n",
    "#y_train with a (10,4) shape instead of (10,1)\n",
    "y_ = np.array(train_labels)\n",
    "y = np.zeros((I,J))\n",
    "for i in range(I):\n",
    "    y[i][y_[i]]=1\n",
    "    \n",
    "#X_test with (0,1) values\n",
    "X_test =  np.array(test_images)/255\n",
    "\n",
    "#y_test with a (10,4) shape instead of (10,1)\n",
    "y_test_ = np.array(test_labels)\n",
    "y_test = np.zeros((I_test,J))\n",
    "for i in range(I_test):\n",
    "    y_test[i][y_test_[i]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #3 Functions, Forward Propagation and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / len(y_true)\n",
    "\n",
    "\n",
    "def FWP(X_b, V, W, y, datasize):\n",
    "    #Activated output of the hidden layer\n",
    "    X_bb = np.dot(X_b,V)         #(I x K) \n",
    "    #F  = ReLU(X_bb)              #(I x K) \n",
    "    F = 1/(1+np.exp(-X_bb))\n",
    "    \n",
    "    #Adding the bias\n",
    "    F0 = np.ones((datasize,1))\n",
    "    F_b = np.concatenate((F0,F), axis=1)\n",
    "    \n",
    "    #Activated output of the output layer\n",
    "    F_bb = np.dot(F_b,W)         #(I x J)\n",
    "    G = softmax(F_bb)            #(I x J)\n",
    "    \n",
    "    #Error computation\n",
    "    error = cross_entropy_loss(G, y)\n",
    "    \n",
    "    return X_bb, F, F_b, F_bb, G, error\n",
    "    \n",
    "\n",
    "def BP(G, X_b, F, F_b, V, W, y):\n",
    "    #More explanation in the ReadMe\n",
    "    #Gradient descent for the W weights\n",
    "    tmp1 = (G-y)*G*(1-G)\n",
    "    dEdW = np.dot(F_b.T,tmp1)\n",
    "    W -= alpha1*dEdW\n",
    "    \n",
    "    #Gradient descent for the V weights\n",
    "    tmp2 = np.dot(tmp1,W[1:].T) *  F * (1-F)\n",
    "    dEdV = np.dot(X_b.T, tmp2)\n",
    "    V -= alpha2*dEdV\n",
    "    \n",
    "    return V, W\n",
    "\n",
    "#Comparing estimation and reality\n",
    "def howManyLinesAreTheSame(Y_pred, Y):\n",
    "    same_lines = Y_pred == Y\n",
    "    nb_of_same_lines = np.sum(same_lines)\n",
    "    return nb_of_same_lines\n",
    "\n",
    "# Training the data\n",
    "def train(X_full, y_full, V, W, datasize=I):\n",
    "    \n",
    "    X = X_full[:datasize]\n",
    "    y = y_full[:datasize]\n",
    "    \n",
    "    #Adding the bias\n",
    "    X0 = np.ones((datasize,1))\n",
    "    X_b = np.concatenate((X0,X), axis = 1)\n",
    "    \n",
    "    #First FWP before looping\n",
    "    X_bb, F, F_b, F_bb, G, error = FWP(X_b, V, W, y, datasize)\n",
    "    \n",
    "    #Print some parameters\n",
    "    print('Datasize:', datasize, 'Tresh:', thresh, 'Max itera:',max_itera, 'Learning rates: (', alpha1,',', alpha2,')')\n",
    "\n",
    "    itera = 0\n",
    "    while(thresh < error):\n",
    "        \n",
    "        V, W = BP(G, X_b, F, F_b, V, W, y)\n",
    "        X_bb, F, F_b, F_bb, G, error = FWP(X_b, V, W, y, datasize)\n",
    "        \n",
    "        if(itera%100==0):\n",
    "            print('#',itera, 'Error: ',error)  \n",
    "        \n",
    "        if(itera>max_itera):\n",
    "            break\n",
    "        itera+=1\n",
    "       \n",
    "    #Finish and estimations\n",
    "    print(\"Entrainement termin√©\")\n",
    "    \n",
    "    return G, V, W\n",
    "    \n",
    "def test(X_test, V, W, I_test):\n",
    "    #Forced to add a bias to get the right shape to FWP it...\n",
    "    X0 = np.ones((I_test,1))\n",
    "    X_b = np.concatenate((X0,X_test), axis = 1)\n",
    "    \n",
    "    #One FWP to get the predictions\n",
    "    X_bb, F, F_b, F_bb, G, error = FWP(X_b, V, W, y_test, I_test)\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #4 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize_ = 60000\n",
    "G_train, V, W = train(X, y, V, W, datasize=datasize_)\n",
    "\n",
    "#Get int values of the predictions\n",
    "G_train_int = np.argmax(G_train, axis=1)\n",
    "print(f'Correct estimation: {howManyLinesAreTheSame(G_train_int, y_)}/{datasize_}', '(',howManyLinesAreTheSame(G_train_int, y_)*100/datasize_,'%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('best_weights/V_weights',V)\n",
    "#np.save('best_weights/W_weights',W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the best weights (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V = np.load('best_weights/V_weights.npy')\n",
    "#W = np.load('best_weights/W_weights.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #5 Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = test(X_test, V, W, I_test)\n",
    "\n",
    "#Get int values of the predictions\n",
    "G_test_int = np.argmax(G_test, axis=1)\n",
    "print(G_test_int)\n",
    "print(f'Correct prediction: {howManyLinesAreTheSame(G_test_int, y_test_)}/{I_test}', '(',howManyLinesAreTheSame(G_test_int, y_test_)*100/I_test,'%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> #6 Playing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "#Grid parameters\n",
    "grid_size = 28\n",
    "cell_size = 20  #Size of each cell in pixels\n",
    "width, height = grid_size * cell_size + 200, grid_size * cell_size + 50  # +200 to display prediction\n",
    "\n",
    "#Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "GRAY = (200, 200, 200)\n",
    "\n",
    "#Initialize pygame\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"Draw a digit\")\n",
    "\n",
    "font = pygame.font.Font(None, 36)\n",
    "\n",
    "#Initialize the grid matrix (28x28) filled with zeros\n",
    "grid = np.zeros((grid_size, grid_size), dtype=np.float32)\n",
    "\n",
    "#Fill only the grid area with black\n",
    "screen.fill(WHITE)\n",
    "pygame.draw.rect(screen, BLACK, (0, 0, grid_size * cell_size, grid_size * cell_size))\n",
    "\n",
    "#Draws the grid lines on the screen\n",
    "def draw_grid():\n",
    "    for x in range(0, grid_size * cell_size, cell_size):\n",
    "        pygame.draw.line(screen, WHITE, (x, 0), (x, grid_size * cell_size))\n",
    "    for y in range(0, grid_size * cell_size, cell_size):\n",
    "        pygame.draw.line(screen, WHITE, (0, y), (grid_size * cell_size, y))\n",
    "\n",
    "#Updates the grid when the user draws, applying a diffusion effect\n",
    "def update_grid(pos):\n",
    "    x, y = pos[0] // cell_size, pos[1] // cell_size\n",
    "    if y < grid_size and x < grid_size:\n",
    "        for dy in range(-1, 2):\n",
    "            for dx in range(-1, 2):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < grid_size and 0 <= ny < grid_size:\n",
    "                    intensity = max(0, 1.0 - (abs(dx) + abs(dy)) * 0.4)  #Gradient effect\n",
    "                    grid[ny, nx] = max(grid[ny, nx], intensity)\n",
    "        \n",
    "        # edraw the grid with updated intensities\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                color_intensity = int(grid[i, j] * 255)\n",
    "                pygame.draw.rect(screen, (color_intensity, color_intensity, color_intensity),\n",
    "                                 (j * cell_size, i * cell_size, cell_size, cell_size))\n",
    "\n",
    "#Draws the erase button\n",
    "def draw_button():\n",
    "    pygame.draw.rect(screen, GRAY, (grid_size * cell_size // 4, grid_size * cell_size + 10, grid_size * cell_size // 2, 30))\n",
    "    text = font.render(\"Erase\", True, BLACK)\n",
    "    screen.blit(text, (grid_size * cell_size // 2 - text.get_width() // 2, grid_size * cell_size + 15))\n",
    "\n",
    "#Clears the grid and resets it to black\n",
    "def clear_grid():\n",
    "    global grid\n",
    "    grid = np.zeros((grid_size, grid_size), dtype=np.float32)\n",
    "    pygame.draw.rect(screen, BLACK, (0, 0, grid_size * cell_size, grid_size * cell_size))\n",
    "    draw_button()\n",
    "\n",
    "drawing = True\n",
    "while drawing:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            drawing = False\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            if grid_size * cell_size + 10 <= event.pos[1] <= grid_size * cell_size + 40:\n",
    "                clear_grid()\n",
    "        elif pygame.mouse.get_pressed()[0]:  # Left mouse button pressed\n",
    "            update_grid(pygame.mouse.get_pos())\n",
    "    \n",
    "    #draw_grid()\n",
    "    draw_button()\n",
    "    \n",
    "    # Normalize the grid values\n",
    "    normalized_grid = grid / np.max(grid) if np.max(grid) > 0 else grid\n",
    "    flattened_grid = normalized_grid.flatten().reshape(1, 784)  # Format (1, 784)\n",
    "    \n",
    "    # Run digit recognition model \n",
    "    G_dessin = test(flattened_grid, V, W, 1)\n",
    "    max_index = np.argmax(G_dessin)  # Get the highest predicted digit\n",
    "    \n",
    "    # Display prediction\n",
    "    pygame.draw.rect(screen, WHITE, (grid_size * cell_size + 10, 10, 180, 50))  # Clear previous prediction\n",
    "    text = font.render(f\"Prediction: {max_index}\", True, BLACK)\n",
    "    screen.blit(text, (grid_size * cell_size + 20, 20))\n",
    "    \n",
    "    pygame.display.flip()\n",
    "\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
